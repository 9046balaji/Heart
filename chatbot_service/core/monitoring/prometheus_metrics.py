"""
Prometheus Metrics Exporter for RAG System

Exports metrics for:
- Memory performance (cache hits, memory usage, LRU operations)
- RAG retrieval (vector search, graph search, fusion retrieval)
- Document compression (compression ratios, reduction metrics)
- LLM operations (token usage, latency)
- Health checks (system status, dependencies)

Integration with Prometheus:
- Metrics exported in Prometheus text format
- Can be scraped via /metrics endpoint (add to FastAPI)
- Ready for Grafana dashboard integration
"""

import time
import logging
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, field
from enum import Enum
import threading
from datetime import datetime

logger = logging.getLogger(__name__)


class MetricType(Enum):
    """Prometheus metric types."""
    COUNTER = "counter"           # Only increases (requests, errors)
    GAUGE = "gauge"               # Can increase or decrease (memory, cache size)
    HISTOGRAM = "histogram"        # Distribution of values (latencies, sizes)
    SUMMARY = "summary"            # Quantile-based distribution


@dataclass
class MetricValue:
    """Container for metric value with metadata."""
    name: str
    value: float
    metric_type: MetricType
    help_text: str
    labels: Dict[str, str] = field(default_factory=dict)
    timestamp: float = field(default_factory=time.time)


class PrometheusMetrics:
    """
    Central metrics collection and export for RAG system.
    
    Tracks:
    - Memory system metrics (cache, LRU)
    - RAG pipeline metrics (retrieval, compression)
    - System health metrics
    """
    
    def __init__(self):
        """Initialize metrics collector."""
        self.metrics: Dict[str, MetricValue] = {}
        self.lock = threading.Lock()
        self._init_metrics()
        logger.info("âœ… PrometheusMetrics initialized")
    
    def _init_metrics(self):
        """Initialize all metrics."""
        # Memory metrics
        self._register_metric(
            "rag_memory_cache_hits",
            MetricType.COUNTER,
            "Total cache hits in RAG memory system"
        )
        self._register_metric(
            "rag_memory_cache_misses",
            MetricType.COUNTER,
            "Total cache misses in RAG memory system"
        )
        self._register_metric(
            "rag_memory_cache_size_bytes",
            MetricType.GAUGE,
            "Current size of RAG memory cache in bytes"
        )
        self._register_metric(
            "rag_memory_lru_evictions",
            MetricType.COUNTER,
            "Total LRU evictions from memory cache"
        )
        
        # Retrieval metrics
        self._register_metric(
            "rag_vector_search_duration_ms",
            MetricType.HISTOGRAM,
            "Vector search operation duration in milliseconds"
        )
        self._register_metric(
            "rag_vector_search_results",
            MetricType.GAUGE,
            "Number of results from vector search"
        )
        self._register_metric(
            "rag_graph_search_duration_ms",
            MetricType.HISTOGRAM,
            "Graph search operation duration in milliseconds"
        )
        self._register_metric(
            "rag_fusion_search_duration_ms",
            MetricType.HISTOGRAM,
            "Fusion retrieval operation duration in milliseconds"
        )
        
        # Compression metrics
        self._register_metric(
            "rag_compression_ratio",
            MetricType.GAUGE,
            "Document compression ratio (0.0-1.0)"
        )
        self._register_metric(
            "rag_compression_operations",
            MetricType.COUNTER,
            "Total document compression operations"
        )
        self._register_metric(
            "rag_compression_failures",
            MetricType.COUNTER,
            "Failed compression operations"
        )
        
        # LLM metrics
        self._register_metric(
            "rag_llm_tokens_input",
            MetricType.COUNTER,
            "Total input tokens sent to LLM"
        )
        self._register_metric(
            "rag_llm_tokens_output",
            MetricType.COUNTER,
            "Total output tokens generated by LLM"
        )
        self._register_metric(
            "rag_llm_latency_ms",
            MetricType.HISTOGRAM,
            "LLM API call latency in milliseconds"
        )
        self._register_metric(
            "rag_llm_errors",
            MetricType.COUNTER,
            "Total LLM API errors"
        )
        
        # Health metrics
        self._register_metric(
            "rag_health_check_passed",
            MetricType.GAUGE,
            "Health check result (1=passed, 0=failed)"
        )
        self._register_metric(
            "rag_trust_validation_errors",
            MetricType.COUNTER,
            "Total trust layer validation errors"
        )
        self._register_metric(
            "rag_conflict_detections",
            MetricType.COUNTER,
            "Total medical conflicts detected"
        )
        
        # System metrics
        self._register_metric(
            "rag_system_uptime_seconds",
            MetricType.GAUGE,
            "System uptime in seconds"
        )
        self._register_metric(
            "rag_active_requests",
            MetricType.GAUGE,
            "Current number of active requests"
        )
    
    def _register_metric(self, name: str, metric_type: MetricType, help_text: str):
        """Register a new metric."""
        with self.lock:
            if name not in self.metrics:
                self.metrics[name] = MetricValue(
                    name=name,
                    value=0.0,
                    metric_type=metric_type,
                    help_text=help_text
                )
    
    def increment_counter(self, metric_name: str, value: float = 1.0, labels: Optional[Dict[str, str]] = None):
        """Increment a counter metric."""
        with self.lock:
            if metric_name in self.metrics:
                metric = self.metrics[metric_name]
                metric.value += value
                if labels:
                    metric.labels.update(labels)
                logger.debug(f"Counter {metric_name} incremented to {metric.value}")
    
    def set_gauge(self, metric_name: str, value: float, labels: Optional[Dict[str, str]] = None):
        """Set a gauge metric value."""
        with self.lock:
            if metric_name in self.metrics:
                metric = self.metrics[metric_name]
                metric.value = value
                if labels:
                    metric.labels = labels
                logger.debug(f"Gauge {metric_name} set to {value}")
    
    def record_histogram(self, metric_name: str, value: float, labels: Optional[Dict[str, str]] = None):
        """Record a histogram value."""
        with self.lock:
            if metric_name in self.metrics:
                metric = self.metrics[metric_name]
                # Store histogram value (for aggregation)
                metric.value = value
                if labels:
                    metric.labels.update(labels)
                logger.debug(f"Histogram {metric_name} recorded value {value}")
    
    def record_memory_hit(self):
        """Record a memory cache hit."""
        self.increment_counter("rag_memory_cache_hits")
    
    def record_memory_miss(self):
        """Record a memory cache miss."""
        self.increment_counter("rag_memory_cache_misses")
    
    def set_cache_size(self, size_bytes: int):
        """Set current cache size."""
        self.set_gauge("rag_memory_cache_size_bytes", float(size_bytes))
    
    def record_eviction(self):
        """Record LRU eviction."""
        self.increment_counter("rag_memory_lru_evictions")
    
    def record_vector_search(self, duration_ms: float, num_results: int):
        """Record vector search operation."""
        self.record_histogram("rag_vector_search_duration_ms", duration_ms)
        self.set_gauge("rag_vector_search_results", float(num_results))
    
    def record_graph_search(self, duration_ms: float):
        """Record graph search operation."""
        self.record_histogram("rag_graph_search_duration_ms", duration_ms)
    
    def record_fusion_search(self, duration_ms: float):
        """Record fusion retrieval operation."""
        self.record_histogram("rag_fusion_search_duration_ms", duration_ms)
    
    def record_compression(self, ratio: float, success: bool = True):
        """Record compression operation."""
        self.set_gauge("rag_compression_ratio", ratio)
        self.increment_counter("rag_compression_operations")
        if not success:
            self.increment_counter("rag_compression_failures")
    
    def record_llm_tokens(self, input_tokens: int, output_tokens: int):
        """Record LLM token usage."""
        self.increment_counter("rag_llm_tokens_input", float(input_tokens))
        self.increment_counter("rag_llm_tokens_output", float(output_tokens))
    
    def record_llm_latency(self, latency_ms: float):
        """Record LLM API latency."""
        self.record_histogram("rag_llm_latency_ms", latency_ms)
    
    def record_llm_error(self):
        """Record LLM API error."""
        self.increment_counter("rag_llm_errors")
    
    def set_health_status(self, passed: bool):
        """Set health check status."""
        self.set_gauge("rag_health_check_passed", 1.0 if passed else 0.0)
    
    def record_validation_error(self):
        """Record trust validation error."""
        self.increment_counter("rag_trust_validation_errors")
    
    def record_conflict_detection(self):
        """Record conflict detection."""
        self.increment_counter("rag_conflict_detections")
    
    def set_uptime(self, seconds: float):
        """Set system uptime."""
        self.set_gauge("rag_system_uptime_seconds", seconds)
    
    def set_active_requests(self, count: int):
        """Set active request count."""
        self.set_gauge("rag_active_requests", float(count))
    
    def export_prometheus(self) -> str:
        """
        Export all metrics in Prometheus text format.
        
        Format:
        # HELP metric_name Description
        # TYPE metric_name metric_type
        metric_name value timestamp
        
        Returns:
            Prometheus-formatted metrics string
        """
        output_lines = []
        
        with self.lock:
            # Group metrics by type for better organization
            by_type = {}
            for metric in self.metrics.values():
                metric_type = metric.metric_type.value
                if metric_type not in by_type:
                    by_type[metric_type] = []
                by_type[metric_type].append(metric)
            
            # Export in order
            for metric_type in [t.value for t in MetricType]:
                if metric_type not in by_type:
                    continue
                
                for metric in by_type[metric_type]:
                    # Add HELP and TYPE comments
                    output_lines.append(f"# HELP {metric.name} {metric.help_text}")
                    output_lines.append(f"# TYPE {metric.name} {metric.metric_type.value}")
                    
                    # Format metric with labels if present
                    if metric.labels:
                        label_str = ",".join(f'{k}="{v}"' for k, v in metric.labels.items())
                        output_lines.append(
                            f"{metric.name}{{{label_str}}} {metric.value} {int(metric.timestamp * 1000)}"
                        )
                    else:
                        output_lines.append(
                            f"{metric.name} {metric.value} {int(metric.timestamp * 1000)}"
                        )
        
        return "\n".join(output_lines) + "\n"
    
    def get_metrics_dict(self) -> Dict[str, Dict[str, Any]]:
        """Get metrics as dictionary for programmatic access."""
        with self.lock:
            return {
                name: {
                    "value": metric.value,
                    "type": metric.metric_type.value,
                    "help": metric.help_text,
                    "labels": metric.labels,
                    "timestamp": metric.timestamp
                }
                for name, metric in self.metrics.items()
            }


# Global singleton instance
_metrics_instance: Optional[PrometheusMetrics] = None


def get_metrics() -> PrometheusMetrics:
    """Get or create global metrics instance."""
    global _metrics_instance
    if _metrics_instance is None:
        _metrics_instance = PrometheusMetrics()
    return _metrics_instance


def reset_metrics():
    """Reset metrics (for testing)."""
    global _metrics_instance
    _metrics_instance = None

